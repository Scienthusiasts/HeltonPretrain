import numpy as np
import torch
from PIL import Image, ImageFile
import torch.utils.data.dataset as data
from torch.utils.data import DataLoader
from functools import partial
import matplotlib.pyplot as plt
import os
import torch.distributed as dist
# è‡ªå®šä¹‰
from heltonx.utils.register import DATASETS
from heltonx.utils.utils import seed_everything, worker_init_fn, natural_key
from pretrain.datasets.preprocess import Transforms
# å…è®¸åŠ è½½æˆªæ–­çš„å›¾åƒ
ImageFile.LOAD_TRUNCATED_IMAGES = True







@DATASETS.register
class INDataset(data.Dataset):      
    '''æœ‰ç›‘ç£åˆ†ç±»ä»»åŠ¡å¯¹åº”çš„åŸºäºImageNetæ•°æ®é›†ç»„ç»‡æ ¼å¼çš„è¯»å–æ–¹å¼
    root
    â”œâ”€train
    â”‚  â”œâ”€class_1
    â”‚  â”œâ”€... ...
    â”‚  â””â”€class_n
    â””â”€valid
        â”œâ”€class_1
        â”œâ”€... ...
        â””â”€class_n
    '''
    def __init__(self, img_dir, mode, img_size, drop_block=True):    
        '''__init__() ä¸ºé»˜è®¤æ„é€ å‡½æ•°ï¼Œä¼ å…¥æ•°æ®é›†ç±»åˆ«ï¼ˆè®­ç»ƒæˆ–æµ‹è¯•ï¼‰ï¼Œä»¥åŠæ•°æ®é›†è·¯å¾„

        Args:
            img_dir:      å›¾åƒæ•°æ®é›†çš„æ ¹ç›®å½•
            mode:     æ¨¡å¼(train/valid)
            img_size: ç½‘ç»œè¦æ±‚è¾“å…¥çš„å›¾åƒå°ºå¯¸

        '''      
        # è®­ç»ƒæ—¶æ˜¯å¦å¯ç”¨drop_blockå¢å¼º
        self.drop_block = drop_block
        # è®°å½•æ•°æ®é›†å¤§å°
        self.data_size = 0             
        # è®­ç»ƒ/éªŒè¯ 
        assert mode in ('train', 'valid'), "mode must be 'train' or 'valid'"
        self.mode = mode              
        # æ•°æ®é¢„å¤„ç†æ–¹æ³•
        self.transform = Transforms(img_size=img_size)
        # éå†æ‰€æœ‰ç±»åˆ«
        self.img_path_list, self.label_list = [], []
        '''å¯¹ç±»è¿›è¡Œæ’åºï¼Œå¾ˆé‡è¦!!!ï¼Œå¦åˆ™ä¼šé€ æˆåˆ†ç±»æ—¶æ ‡ç­¾åŒ¹é…ä¸ä¸Šå¯¼è‡´è¯„ä¼°çš„ç²¾åº¦å¾ˆä½'''
        # åªæŠŠç›®å½•å½“æˆç±»åˆ«(è¿‡æ»¤æ–‡ä»¶ã€éšè—ç›®å½•)
        all_entries = [d for d in os.listdir(img_dir) if os.path.isdir(os.path.join(img_dir, d)) and not d.startswith('.')]
        self.cat_names = sorted(all_entries, key=natural_key)
        # æ•°æ®é›†ç±»åˆ«æ•°      
        self.labels_num = len(self.cat_names)   
        # è®°å½•æ•°æ®é›†æ‰€æœ‰å›¾ç‰‡çš„è·¯å¾„å’Œå¯¹åº”çš„ç±»åˆ«
        for idx, cat in enumerate(self.cat_names):
            cat_path = os.path.join(img_dir, cat)
            label_files = os.listdir(cat_path)
            # æ¯ä¸ªç±»åˆ«é‡Œå›¾åƒæ•°
            length = len(label_files)
            # å­˜æ”¾å›¾ç‰‡è·¯å¾„
            self.img_path_list += [os.path.join(cat_path, label_files[i]) for i in range(length)]
            # å­˜æ”¾å›¾ç‰‡å¯¹åº”çš„æ ‡ç­¾(æ ¹æ®æ‰€åœ¨æ–‡ä»¶å¤¹åˆ’åˆ†)
            self.label_list += [idx for _ in range(length)]
            self.data_size += length        
        
        # æ‰“å°æ•°æ®é›†ä¿¡æ¯
        use_ddp = dist.is_initialized()
        if not use_ddp or use_ddp and dist.get_rank() == 0:
            print(f'ğŸ“„  dataset info: mode:{mode}, å›¾åƒæ•°:{self.__len__()}, ç±»åˆ«æ•°:{self.get_cls_num()}')


    def __getitem__(self, item):  
        '''é‡è½½data.Datasetçˆ¶ç±»æ–¹æ³•, è·å–æ•°æ®é›†ä¸­æ•°æ®å†…å®¹
        '''   
        # è¯»å–å›¾ç‰‡
        img = Image.open(self.img_path_list[item]).convert('RGB')     
        img = np.array(img)
        # è·å–imageå¯¹åº”çš„label
        label = self.label_list[item]                 
        # æ•°æ®é¢„å¤„ç†/æ•°æ®å¢å¼º
        if self.mode=='train':
            img, _ = self.train_aug(img)
        if self.mode=='valid':
            img = self.normal_aug(img)  

        return img.transpose(2,0,1), label
    

    def train_aug(self, img, train_transform=None):
        """è®­ç»ƒæ—¶æ•°æ®å¢å¼º
        """
        # albumentationçš„å›¾åƒç»´åº¦å¾—æ˜¯[W,H,C]
        if train_transform==None:
            train_transform = self.transform.train_transform(image=img)
        img = train_transform['image']
        if self.drop_block:
            coarseDropTrans = self.transform.CoarseDropout(image=img)
            img = coarseDropTrans['image']
        img = self.normal_aug(img)
        return img, train_transform


    def normal_aug(self, img):
        """åŸºç¡€æ•°æ®é¢„å¤„ç†
        """
        norm_trans = self.transform.valid_transform(image=img)          
        img = norm_trans['image']   
        return img

    def __len__(self):
        '''é‡è½½data.Datasetçˆ¶ç±»æ–¹æ³•, è¿”å›æ•°æ®é›†å¤§å°
        '''
        return self.data_size
    
    def get_cls_num(self):
        '''è¿”å›æ•°æ®é›†ç±»åˆ«æ•°
        '''
        return self.labels_num

    # DataLoaderä¸­collate_fnå‚æ•°ä½¿ç”¨
    # ç”±äºæ£€æµ‹æ•°æ®é›†æ¯å¼ å›¾åƒä¸Šçš„ç›®æ ‡æ•°é‡ä¸ä¸€
    # å› æ­¤éœ€è¦è‡ªå®šä¹‰çš„å¦‚ä½•ç»„ç»‡ä¸€ä¸ªbatché‡Œè¾“å‡ºçš„å†…å®¹
    def dataset_collate(self, batch):
        images, labels = [], []
        for img, label in batch:
            images.append(img)
            labels.append(label)
        # np -> tensor
        images  = torch.from_numpy(np.array(images)).type(torch.FloatTensor)
        labels  = torch.from_numpy(np.array(labels)).type(torch.LongTensor)
        return images, labels


    # for debug only:
    def _vis_INDataset_batch(self, epoch, step, batch, cat_names):
        '''å¯è§†åŒ–è®­ç»ƒé›†ä¸€ä¸ªbatch
        Args:
            cat_names:   list, ç±»åˆ«å
        Retuens:
            None     
        '''
        # å›¾åƒå‡å€¼ æ ‡å‡†å·®
        mean = np.array([0.485, 0.456, 0.406]) 
        std = np.array([[0.229, 0.224, 0.225]]) 

        imgs = batch[0]
        labels = batch[1]
        plt.figure(figsize = (8,8))
        for idx, [img, label] in enumerate(zip(imgs, labels)):
            img = img.numpy().transpose((1,2,0))
            img = img * std + mean
            plt.subplot(8,8,idx+1)
            plt.imshow(img)
            plt.title(cat_names[label], fontsize=8)
            plt.axis("off")
            # å¾®è°ƒè¡Œé—´è·
            plt.subplots_adjust(left=0.01, bottom=0.01, right=0.99, top=0.97, wspace=0.01, hspace=0.2)

        plt.savefig(f'./epoch{epoch}_step{step}.jpg', dpi=300)








# for test only
if __name__ == '__main__':

    # é…ç½®å­—å…¸
    img_dir = r'/mnt/yht/data/The_Oxford_IIIT_Pet_Dataset/images/train'
    cfg = {
        "dataset_cfg": {
            "type": "INDataset",
            "img_dir": img_dir,
            "mode": "train",
            "img_size": [224, 224],
            "drop_block": False
        },
        "bs": 64,
        "seed": 42,
        "shuffle": True
    }

    dataset_cfg = cfg["dataset_cfg"]
    seed_everything(cfg["seed"])
    train_dataset = DATASETS.build_from_cfg(dataset_cfg)
    print(f'æ•°æ®é›†å¤§å°:{train_dataset.__len__()}')
    print(f'æ•°æ®é›†ç±»åˆ«æ•°:{train_dataset.get_cls_num()}')
    train_data_loader = DataLoader(dataset=train_dataset, batch_size=cfg["bs"], shuffle=cfg["shuffle"], num_workers=8, collate_fn=train_dataset.dataset_collate, worker_init_fn=partial(worker_init_fn, seed=cfg["seed"]))
    # è·å–label name
    cat_names = sorted(os.listdir(img_dir))
    print(cat_names)
    # è¾“å‡ºæ•°æ®æ ¼å¼
    for epoch in range(1, 10):
        for step, batch in enumerate(train_data_loader):
            print(batch[0].shape)
            print(batch[1].shape)
            if step == 0:
                # å¯è§†åŒ–ä¸€ä¸ªbatché‡Œçš„å›¾åƒ
                train_dataset._vis_INDataset_batch(epoch, step, batch, cat_names)