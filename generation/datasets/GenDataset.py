import numpy as np
import torch
from PIL import Image, ImageFile
import torch.utils.data.dataset as data
from torch.utils.data import DataLoader
from functools import partial
import matplotlib.pyplot as plt
import os
import torch.distributed as dist
# å…è®¸åŠ è½½æˆªæ–­çš„å›¾åƒ
ImageFile.LOAD_TRUNCATED_IMAGES = True
# è‡ªå®šä¹‰
from heltonx.utils.register import DATASETS
from heltonx.utils.utils import seed_everything, worker_init_fn
from generation.datasets.preprocess import Transforms








@DATASETS.register
class GenDataset(data.Dataset):      
    '''æœ‰ç›‘ç£åˆ†ç±»ä»»åŠ¡å¯¹åº”çš„æ•°æ®é›†è¯»å–æ–¹å¼
    '''
    def __init__(self, img_dir, img_size):    
        '''__init__() ä¸ºé»˜è®¤æ„é€ å‡½æ•°ï¼Œä¼ å…¥æ•°æ®é›†ç±»åˆ«ï¼ˆè®­ç»ƒæˆ–æµ‹è¯•ï¼‰ï¼Œä»¥åŠæ•°æ®é›†è·¯å¾„

        Args:
            :param dir:      å›¾åƒæ•°æ®é›†çš„æ ¹ç›®å½•
            :param mode:     æ¨¡å¼(train/valid)
            :param img_size: ç½‘ç»œè¦æ±‚è¾“å…¥çš„å›¾åƒå°ºå¯¸

        Returns:
            precision, recall
        '''      
        self.img_dir = img_dir
        self.transform = Transforms(img_size=img_size)
        # æ”¯æŒçš„å›¾åƒæ‰©å±•å
        IMG_EXTS = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp')
        # é€’å½’éå†æ‰€æœ‰å­ç›®å½•æ‰¾åˆ°æ‰€æœ‰å›¾åƒæ–‡ä»¶
        self.img_path_list = [
            os.path.join(root, fname)
            for root, _, files in os.walk(self.img_dir)
            for fname in files
            if fname.lower().endswith(IMG_EXTS)
        ]
        # è®°å½•æ•°æ®é›†å¤§å°
        self.dataSize = len(self.img_path_list)

        # æ‰“å°æ•°æ®é›†ä¿¡æ¯
        use_ddp = dist.is_initialized()
        if not use_ddp or use_ddp and dist.get_rank() == 0:
            print(f'ğŸ“„  dataset info: å›¾åƒæ•°:{self.__len__()}')



    def __getitem__(self, item):  
        '''é‡è½½data.Datasetçˆ¶ç±»æ–¹æ³•, è·å–æ•°æ®é›†ä¸­æ•°æ®å†…å®¹
        '''   
        # è¯»å–å›¾ç‰‡
        img = Image.open(self.img_path_list[item]).convert('RGB')     
        img = np.array(img)
        # æ•°æ®å¢å¼º
        img = self.albumAug(img)         
        return img.transpose(2,0,1)
    

    def albumAug(self, img):
        """åŸºäºalbumentationsåº“çš„åŸºç¡€æ•°æ®é¢„å¤„ç†
        """
        trans = self.transform.transform(image=img)          
        img = trans['image']   
        return img


    def __len__(self):
        '''é‡è½½data.Datasetçˆ¶ç±»æ–¹æ³•, è¿”å›æ•°æ®é›†å¤§å°
        '''
        return self.dataSize


    # DataLoaderä¸­collate_fnå‚æ•°ä½¿ç”¨
    # ç”±äºæ£€æµ‹æ•°æ®é›†æ¯å¼ å›¾åƒä¸Šçš„ç›®æ ‡æ•°é‡ä¸ä¸€
    # å› æ­¤éœ€è¦è‡ªå®šä¹‰çš„å¦‚ä½•ç»„ç»‡ä¸€ä¸ªbatché‡Œè¾“å‡ºçš„å†…å®¹
    def dataset_collate(self, batch):
        images = []
        for img in batch:
            images.append(img)
        # np -> tensor
        images = torch.from_numpy(np.array(images)).type(torch.FloatTensor)
        return [images]
    

    # for debug only:
    def _vis_GenDataset_batch(self, epoch, step, batch):
        '''å¯è§†åŒ–è®­ç»ƒé›†ä¸€ä¸ªbatch
        Args:
        Retuens:
            None     
        '''
        # å›¾åƒå‡å€¼ æ ‡å‡†å·®
        mean = np.array([0.485, 0.456, 0.406]) 
        std = np.array([[0.229, 0.224, 0.225]]) 

        imgs = batch
        plt.figure(figsize = (8,8))
        for idx, img in enumerate(imgs):
            img = img.numpy().transpose((1,2,0))
            img = img * std + mean
            plt.subplot(8,8,idx+1)
            plt.imshow(img)
            plt.axis("off")
            # å¾®è°ƒè¡Œé—´è·
            plt.subplots_adjust(left=0.01, bottom=0.01, right=0.99, top=0.97, wspace=0.01, hspace=0.2)

        plt.savefig(f'./epoch{epoch}_step{step}_.jpg', dpi=300)







# for test only
if __name__ == '__main__':

    # é…ç½®å­—å…¸
    img_dir = r'/mnt/yht/data/The_Oxford_IIIT_Pet_Dataset/images'
    cfg = {
        "dataset_cfg": {
            "type": "GenDataset",
            "img_dir": img_dir,
            "img_size": [256, 256]
        },
        "bs": 64,
        "seed": 42,
        "shuffle": True
    }

    dataset_cfg = cfg["dataset_cfg"]
    seed_everything(cfg["seed"])
    train_dataset = DATASETS.build_from_cfg(dataset_cfg)
    train_data_loader = DataLoader(dataset=train_dataset, batch_size=cfg["bs"], shuffle=cfg["shuffle"], num_workers=8, collate_fn=train_dataset.dataset_collate, worker_init_fn=partial(worker_init_fn, seed=cfg["seed"]))
    # è¾“å‡ºæ•°æ®æ ¼å¼
    for epoch in range(1, 10):
        for step, batch in enumerate(train_data_loader):
            print(batch.shape)
            if step == 0:
                # å¯è§†åŒ–ä¸€ä¸ªbatché‡Œçš„å›¾åƒ
                train_dataset._vis_GenDataset_batch(epoch, step, batch)